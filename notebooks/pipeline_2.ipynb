{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "707bfdde",
   "metadata": {},
   "source": [
    "## Construction d'un pipeline MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5949d7a5",
   "metadata": {},
   "source": [
    "Les colonnes selectionnées pour ce pipeline sont:\n",
    "- Type\n",
    "- ShippingMode\n",
    "- LateDeliveryRisk\n",
    "- CategoryName\n",
    "- CustomerSegment\n",
    "- OrderItemTotal\n",
    "- OrderRegion\n",
    "- ShippingMonthName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62b95946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from modules.spark import spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6df1a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"../data/processed/data-initial-cleaning.csv\", header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1bbd7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Type',\n",
       " 'Days for shipment (scheduled)',\n",
       " 'Benefit per order',\n",
       " 'Sales per customer',\n",
       " 'Late_delivery_risk',\n",
       " 'Category Name',\n",
       " 'Customer Segment',\n",
       " 'Department Name',\n",
       " 'Latitude',\n",
       " 'Longitude',\n",
       " 'Market',\n",
       " 'Order Item Discount',\n",
       " 'Order Item Discount Rate',\n",
       " 'Order Item Product Price',\n",
       " 'Order Item Profit Ratio',\n",
       " 'Order Item Quantity',\n",
       " 'Sales',\n",
       " 'Order Item Total',\n",
       " 'Order Profit Per Order',\n",
       " 'Order Region',\n",
       " 'Product Price',\n",
       " 'Shipping Mode',\n",
       " 'Order_Month_Name',\n",
       " 'Shipping_Month_Name']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0643c15e",
   "metadata": {},
   "source": [
    "- Equilibrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0baf5768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|Late_delivery_risk|count|\n",
      "+------------------+-----+\n",
      "|                 1|98977|\n",
      "|                 0|73788|\n",
      "+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Late_delivery_risk').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80b7fbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73788\n",
      "73579\n"
     ]
    }
   ],
   "source": [
    "class_0 = df.filter(F.col(\"Late_delivery_risk\") == 0)\n",
    "class_1 = df.filter(F.col(\"Late_delivery_risk\") == 1)\n",
    "\n",
    "ratio = class_0.count() / class_1.count()\n",
    "\n",
    "new_class_1 = class_1.sample(withReplacement=False, fraction=ratio)\n",
    "\n",
    "df_balanced = class_0.union(new_class_1)\n",
    "\n",
    "new_class_0 = df_balanced.filter(F.col(\"Late_delivery_risk\") == 0).count()\n",
    "new_class_1 = df_balanced.filter(F.col(\"Late_delivery_risk\") == 1).count()\n",
    "\n",
    "print(new_class_0)\n",
    "print(new_class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba57685",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    # Target\n",
    "    'Late_delivery_risk',\n",
    "\n",
    "    # 'Shipping Mode',\n",
    "    # 'Type',\n",
    "    # 'Category Name',\n",
    "    # 'Customer Segment',\n",
    "    # 'Order Item Quantity', \n",
    "    # 'Shipping_Month_Name',\n",
    "    # 'Order_Month_Name',\n",
    "    # 'Order Item Total',\n",
    "\n",
    "    # 'Order_Month_Name',\n",
    "    # 'Shipping_Month_Name',\n",
    "    # 'Order Item Quantity',\n",
    "    # 'Type',\n",
    "    # 'Product Price',\n",
    "    # 'Customer Segment',\n",
    "    # 'Shipping Mode',\n",
    "    # 'Order Item Total'\n",
    "\n",
    "    'Shipping_Month_Name', 'Category Name', 'Customer Segment', 'Shipping Mode', 'Type', 'Order_Month_Name'\n",
    "    # 'Order_Month_Name', 'Shipping_Month_Name', 'Order Item Quantity', 'Type', 'Product Price', 'Customer Segment', 'Shipping Mode', 'Benefit per order', 'Order Item Total'\n",
    "    # 'Order_Month_Name',\n",
    "    # 'Shipping_Month_Name',\n",
    "    # 'Order Item Quantity',\n",
    "    # 'Type',\n",
    "    # 'Product Price',\n",
    "    # 'Customer Segment',\n",
    "    # 'Shipping Mode',\n",
    "    # 'Order Item Total'\n",
    "]\n",
    "\n",
    "df_col_select = df_balanced.select(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee03d720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Late_delivery_risk', 'Shipping Mode']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_col_select.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807a10aa",
   "metadata": {},
   "source": [
    "- Separer les noms de colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0c92850",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_cols = []\n",
    "int_cols = []\n",
    "\n",
    "for c, t in df_col_select.dtypes[1:]:\n",
    "    if (t == 'string'):\n",
    "        string_cols.append(c)\n",
    "    else:\n",
    "        int_cols.append(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc0157f",
   "metadata": {},
   "source": [
    "### Assembler le pipeline MLlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98aed36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, VectorAssembler, StringIndexer, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=c, outputCol=c+\"_index\") for c in string_cols\n",
    "]\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[c+'_index' for c in string_cols],\n",
    "    outputCols=[c+'_vec' for c in string_cols]\n",
    ")\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[c for c in int_cols] + [c+'_vec' for c in string_cols],\n",
    "    outputCol='features'\n",
    ")\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features\",\n",
    "    outputCol='scaled_features',\n",
    "    withMean=True,\n",
    "    withStd=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806585b9",
   "metadata": {},
   "source": [
    "- Division de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f43880c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = df_col_select.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c22a6d2",
   "metadata": {},
   "source": [
    "### Entrainement des modéles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f414b455",
   "metadata": {},
   "source": [
    "- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbd55274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier(labelCol=\"Late_delivery_risk\", featuresCol=\"scaled_features\")\n",
    "\n",
    "rf_pipeline = Pipeline(stages=indexers + [encoder, assembler, scaler, rf])\n",
    "\n",
    "rf_model = rf_pipeline.fit(train_df)\n",
    "rf_predictions = rf_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec770fb8",
   "metadata": {},
   "source": [
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73afb7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"Late_delivery_risk\", featuresCol=\"scaled_features\")\n",
    "\n",
    "lr_pipeline = Pipeline(stages=indexers + [encoder, assembler, scaler, lr])\n",
    "\n",
    "lr_model = lr_pipeline.fit(train_df)\n",
    "lr_predictions = lr_model.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff345d2b",
   "metadata": {},
   "source": [
    "- GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8cda557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "gb = GBTClassifier(labelCol=\"Late_delivery_risk\", featuresCol=\"scaled_features\")\n",
    "\n",
    "gb_pipeline = Pipeline(stages=indexers + [encoder, assembler, scaler, gb])\n",
    "\n",
    "gb_model = gb_pipeline.fit(train_df)\n",
    "gb_predictions = gb_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba924f",
   "metadata": {},
   "source": [
    "### Evaluation de performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1961d901",
   "metadata": {},
   "source": [
    "- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38abd9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# évaluer les prédictions\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"Late_delivery_risk\",     # vraie étiquette\n",
    "    rawPredictionCol=\"rawPrediction\",  # par défaut\n",
    "    metricName=\"areaUnderROC\"  # ou \"areaUnderPR\"\n",
    ")\n",
    "\n",
    "rf_auc = evaluator.evaluate(rf_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c47f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# accuracy\n",
    "acc_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Late_delivery_risk\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "rf_accuracy = acc_eval.evaluate(rf_predictions)\n",
    "\n",
    "# F1-score\n",
    "f1_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Late_delivery_risk\", predictionCol=\"prediction\", metricName=\"f1\"\n",
    ")\n",
    "rf_f1 = f1_eval.evaluate(rf_predictions)\n",
    "\n",
    "precision_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Late_delivery_risk\", predictionCol=\"prediction\", metricName=\"weightedPrecision\"\n",
    ")\n",
    "rf_precision = precision_eval.evaluate(rf_predictions)\n",
    "\n",
    "recall_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Late_delivery_risk\", predictionCol=\"prediction\", metricName=\"weightedRecall\"\n",
    ")\n",
    "rf_recall = recall_eval.evaluate(rf_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94419b88",
   "metadata": {},
   "source": [
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbb91e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# évaluer les prédictions\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"Late_delivery_risk\",     # vraie étiquette\n",
    "    rawPredictionCol=\"rawPrediction\",  # par défaut\n",
    "    metricName=\"areaUnderROC\"  # ou \"areaUnderPR\"\n",
    ")\n",
    "\n",
    "lr_auc = evaluator.evaluate(lr_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9de7b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# accuracy\n",
    "acc_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Late_delivery_risk\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "lr_accuracy = acc_eval.evaluate(lr_predictions)\n",
    "\n",
    "# F1-score\n",
    "f1_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Late_delivery_risk\", predictionCol=\"prediction\", metricName=\"f1\"\n",
    ")\n",
    "lr_f1 = f1_eval.evaluate(lr_predictions)\n",
    "\n",
    "# Precision\n",
    "precision_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Late_delivery_risk\", predictionCol=\"prediction\", metricName=\"weightedPrecision\"\n",
    ")\n",
    "lr_precision = precision_eval.evaluate(lr_predictions)\n",
    "\n",
    "# F1-score\n",
    "recall_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Late_delivery_risk\", predictionCol=\"prediction\", metricName=\"weightedRecall\"\n",
    ")\n",
    "lr_recall = recall_eval.evaluate(lr_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1303c423",
   "metadata": {},
   "source": [
    "- GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12514185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# évaluer les prédictions\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"Late_delivery_risk\",     # vraie étiquette\n",
    "    rawPredictionCol=\"rawPrediction\",  # par défaut\n",
    "    metricName=\"areaUnderROC\"  # ou \"areaUnderPR\"\n",
    ")\n",
    "\n",
    "gb_auc = evaluator.evaluate(gb_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba7685bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# accuracy\n",
    "acc_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Late_delivery_risk\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "gb_accuracy = acc_eval.evaluate(gb_predictions)\n",
    "\n",
    "# F1-score\n",
    "f1_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Late_delivery_risk\", predictionCol=\"prediction\", metricName=\"f1\"\n",
    ")\n",
    "gb_f1 = f1_eval.evaluate(gb_predictions)\n",
    "\n",
    "# F1-score\n",
    "precision_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Late_delivery_risk\", predictionCol=\"prediction\", metricName=\"weightedPrecision\"\n",
    ")\n",
    "gb_precision = precision_eval.evaluate(gb_predictions)\n",
    "\n",
    "# F1-score\n",
    "recall_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Late_delivery_risk\", predictionCol=\"prediction\", metricName=\"weightedRecall\"\n",
    ")\n",
    "gb_recall = recall_eval.evaluate(gb_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaa6438",
   "metadata": {},
   "source": [
    "- Sauvegardez le modèle (pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1c801bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gb_model.write().overwrite().save('../models/model_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6e261a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- LR\n",
      "AUC = 0.744\n",
      "Accuracy = 0.725\n",
      "F1-score = 0.716\n",
      "Precision = 0.761\n",
      "Recall = 0.725\n",
      "\n",
      "------------- RF\n",
      "AUC = 0.744\n",
      "Accuracy = 0.725\n",
      "F1-score = 0.716\n",
      "Precision = 0.761\n",
      "Recall = 0.725\n",
      "\n",
      "------------- GBT\n",
      "AUC = 0.744\n",
      "Accuracy = 0.725\n",
      "F1-score = 0.716\n",
      "Precision = 0.761\n",
      "Recall = 0.725\n"
     ]
    }
   ],
   "source": [
    "print(\"------------- LR\")\n",
    "print(f\"AUC = {lr_auc:.3f}\")\n",
    "print(f\"Accuracy = {lr_accuracy:.3f}\")\n",
    "print(f\"F1-score = {lr_f1:.3f}\")\n",
    "print(f\"Precision = {lr_precision:.3f}\")\n",
    "print(f\"Recall = {lr_recall:.3f}\")\n",
    "\n",
    "print(\"\\n------------- RF\")\n",
    "print(f\"AUC = {rf_auc:.3f}\")\n",
    "print(f\"Accuracy = {rf_accuracy:.3f}\")\n",
    "print(f\"F1-score = {rf_f1:.3f}\")\n",
    "print(f\"Precision = {rf_precision:.3f}\")\n",
    "print(f\"Recall = {rf_recall:.3f}\")\n",
    "\n",
    "print(\"\\n------------- GBT\")\n",
    "print(f\"AUC = {gb_auc:.3f}\")\n",
    "print(f\"Accuracy = {gb_accuracy:.3f}\")\n",
    "print(f\"F1-score = {gb_f1:.3f}\")\n",
    "print(f\"Precision = {gb_precision:.3f}\")\n",
    "print(f\"Recall = {gb_recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077842ab",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07fdc0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce9dfe1",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e99bfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.feature import OneHotEncoder, VectorAssembler, StringIndexer, StandardScaler\n",
    "# from pyspark.ml import Pipeline\n",
    "# from pyspark.ml.classification import RandomForestClassifier\n",
    "# from pyspark.ml.classification import LogisticRegression\n",
    "# from pyspark.ml.classification import GBTClassifier\n",
    "# from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "# important_cols = [\n",
    "#     # Target\n",
    "#     'Late_delivery_risk',\n",
    "\n",
    "#     # Important Columns\n",
    "# ]\n",
    "\n",
    "# extra_cols = [\n",
    "#     'Shipping Mode',\n",
    "#     'Type',\n",
    "#     'Category Name',\n",
    "#     'Customer Segment',\n",
    "#     'Order Item Total',\n",
    "#     'Benefit per order',\n",
    "#     'Order_Month_Name',\n",
    "#     'Shipping_Month_Name',\n",
    "#     'Order Region',\n",
    "#     'Product Price',\n",
    "#     'Order Item Quantity',\n",
    "# ]\n",
    "\n",
    "\n",
    "# result = {\n",
    "#     \"acc\": 0,\n",
    "#     \"col\": []\n",
    "# }\n",
    "\n",
    "# history = []\n",
    "\n",
    "# for a in range(len(extra_cols)):\n",
    "#     for b in range(a+1, len(extra_cols)):\n",
    "#         for c in range(b+1, len(extra_cols)):\n",
    "#             for d in range(c+1, len(extra_cols)):\n",
    "#                 for e in range(d+1, len(extra_cols)):\n",
    "#                     for f in range(e, len(extra_cols)):\n",
    "#                         for g in range(f, len(extra_cols)):\n",
    "#                             for h in range(g, len(extra_cols)):\n",
    "#                                 for i in range(h, len(extra_cols)):\n",
    "\n",
    "#                                     indexes = set([a, b, c, d, e, f, g, h, i])\n",
    "#                                     if (indexes in history):\n",
    "#                                         print(a, b, c, d, e, f, g, h, i, ' -- ', 'Skipped')\n",
    "#                                         continue\n",
    "\n",
    "#                                     history.append(indexes)\n",
    "                                    \n",
    "#                                     selected_extra_cols = list(set([extra_cols[a]] + [extra_cols[b]] + [extra_cols[c]] + [extra_cols[d]] + [extra_cols[e]] + [extra_cols[f]] + [extra_cols[g]] + [extra_cols[h]] + [extra_cols[i]]))\n",
    "#                                     select_cols = important_cols + selected_extra_cols\n",
    "                                    \n",
    "#                                     df_col_select = df.select(select_cols)\n",
    "\n",
    "#                                     string_cols = []\n",
    "#                                     int_cols = []\n",
    "\n",
    "#                                     for col, dtype in df_col_select.dtypes[1:]:\n",
    "#                                         if (dtype == 'string'):\n",
    "#                                             string_cols.append(col)\n",
    "#                                         else:\n",
    "#                                             int_cols.append(col)\n",
    "\n",
    "#                                     indexers = [\n",
    "#                                         StringIndexer(inputCol=col, outputCol=col+\"_index\") for col in string_cols\n",
    "#                                     ]\n",
    "#                                     encoder = OneHotEncoder(\n",
    "#                                         inputCols=[col+'_index' for col in string_cols],\n",
    "#                                         outputCols=[col+'_vec' for col in string_cols]\n",
    "#                                     )\n",
    "\n",
    "#                                     assembler = VectorAssembler(\n",
    "#                                         inputCols=[col for col in int_cols] + [col+'_vec' for col in string_cols],\n",
    "#                                         outputCol='features'\n",
    "#                                     )\n",
    "\n",
    "#                                     train_df, test_df = df_col_select.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "#                                     # GBT\n",
    "\n",
    "#                                     gb = GBTClassifier(labelCol=\"Late_delivery_risk\", featuresCol=\"features\")\n",
    "\n",
    "#                                     gb_pipeline = Pipeline(stages=indexers + [encoder, assembler, gb])\n",
    "\n",
    "#                                     gb_model = gb_pipeline.fit(train_df)\n",
    "#                                     gb_predictions = gb_model.transform(test_df)\n",
    "\n",
    "#                                     acc_eval = MulticlassClassificationEvaluator(\n",
    "#                                         labelCol=\"Late_delivery_risk\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    "#                                     )\n",
    "#                                     gb_accuracy = acc_eval.evaluate(gb_predictions)\n",
    "\n",
    "#                                     print(a, b, c, d, e, f, g, h, i, ' - ', gb_accuracy, ' --- ', result['acc'], ' | ', result['col'])\n",
    "\n",
    "#                                     if result[\"acc\"] < gb_accuracy:\n",
    "#                                         result[\"acc\"] = gb_accuracy\n",
    "#                                         result[\"col\"] = selected_extra_cols\n",
    "    \n",
    "# print(\"The best acc\", result[\"acc\"])\n",
    "# print(\"The best col\", result[\"col\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e84f87c",
   "metadata": {},
   "source": [
    "- 0.7000640018618723\n",
    "- ['Order Item Quantity', 'Shipping_Month_Name', 'Order_Month_Name', 'Order Item Total']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a6d5cb",
   "metadata": {},
   "source": [
    "----\n",
    "- 0.70250770931518\n",
    "- ['Shipping_Month_Name', 'Category Name', 'Customer Segment', 'Shipping Mode', 'Type', 'Order_Month_Name']\n",
    "----\n",
    "- 0.7040786641065921\n",
    "- ['Order_Month_Name', 'Shipping_Month_Name', 'Order Item Quantity', 'Type', 'Product Price', 'Customer Segment', 'Shipping Mode', 'Benefit per order', 'Order Item Total']\n",
    "----\n",
    "- 0.7043404899051608\n",
    "- ['Order_Month_Name', 'Shipping_Month_Name', 'Order Item Quantity', 'Type', 'Product Price', 'Customer Segment', 'Shipping Mode', 'Order Item Total']\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
